{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Sensor Data Exploration\n",
    "\n",
    "**Objective:** Understand the structure of the HAR dataset, visualize features, detect inconsistencies, and normalize data.\n",
    "\n",
    "Students will learn how to load real sensor data, explore feature distributions, and prepare it for ML."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load feature and activity info\n",
    "features = pd.read_csv('dataset/features.txt', delim_whitespace=True, header=None)\n",
    "activity_labels = pd.read_csv('dataset/activity_labels.txt', delim_whitespace=True, header=None, index_col=0)\n",
    "\n",
    "# Load training and test data\n",
    "X_train = pd.read_csv('dataset/X_train.txt', delim_whitespace=True, header=None)\n",
    "X_test = pd.read_csv('dataset/X_test.txt', delim_whitespace=True, header=None)\n",
    "y_train = pd.read_csv('dataset/y_train.txt', header=None)\n",
    "y_test = pd.read_csv('dataset/y_test.txt', header=None)\n",
    "\n",
    "# Assign feature names\n",
    "X_train.columns = features[1]\n",
    "X_test.columns = features[1]\n",
    "\n",
    "# Map activity labels\n",
    "y_train_mapped = y_train[0].map(activity_labels[1])\n",
    "y_test_mapped = y_test[0].map(activity_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Dataset\n",
    "- Check dimensions and basic stats\n",
    "- Look for class balance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "print('\\nActivity distribution:')\n",
    "print(y_train_mapped.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Some Features\n",
    "- Histogram of one feature to see distribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example: visualize mean body acceleration magnitude\n",
    "plt.hist(X_train['tBodyAccMag-mean()'], bins=50)\n",
    "plt.title('Distribution of tBodyAccMag-mean()')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization\n",
    "Scaling features is important for both regression and classification because many ML models are sensitive to feature magnitude."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "1. Why is it important to remove the target from features before scaling?\n",
    "2. Why scale the test set using the same scaler as the training set?\n",
    "3. How does class balance affect model training?"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
