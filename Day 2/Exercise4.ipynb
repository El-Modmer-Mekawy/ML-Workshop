{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-ex4",
   "metadata": {},
   "source": [
    "# Exercise 4: Image Data Preparation\n",
    "\n",
    "## Objective\n",
    "Understand how images become numerical data and prepare them for a vision model.\n",
    "\n",
    "We will:\n",
    "- Capture images (robustly, handling cloud environments)\n",
    "- Convert images to numerical arrays\n",
    "- Resize and normalize images\n",
    "- Apply simple data augmentation\n",
    "\n",
    "This is the foundation of computer vision systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q opencv-python-headless matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-1",
   "metadata": {},
   "source": [
    "## Step 1: Capture an Image (The \"Cloud-Safe\" Way)\n",
    "\n",
    "Standard `cv2.VideoCapture(0)` fails in cloud environments (Colab/Kaggle). We use a fallback mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capture-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_image_robust():\n",
    "    # Try to open local webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "        if ret:\n",
    "            print(\"Success: Captured image from local webcam.\")\n",
    "            return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Fallback: Generate a synthetic test pattern\n",
    "    print(\"Warning: Webcam not found (common in cloud). Generating synthetic image.\")\n",
    "    height, width = 480, 640\n",
    "    # Create a gradient image\n",
    "    img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for i in range(3):\n",
    "        img[:, :, i] = np.linspace(0, 255, width)\n",
    "    \n",
    "    # Draw a circle so we can see augmentations later\n",
    "    cv2.circle(img, (320, 240), 100, (255, 255, 0), -1)\n",
    "    return img\n",
    "\n",
    "frame_rgb = get_image_robust()\n",
    "\n",
    "plt.imshow(frame_rgb)\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Image shape:\", frame_rgb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-2",
   "metadata": {},
   "source": [
    "## Step 2: Resize Image\n",
    "\n",
    "Neural networks require fixed input size (e.g., 224x224 for ResNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resize",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)\n",
    "resized = cv2.resize(frame_rgb, target_size)\n",
    "\n",
    "plt.imshow(resized)\n",
    "plt.title(f\"Resized to {target_size}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-3",
   "metadata": {},
   "source": [
    "## Step 3: Normalize Pixels\n",
    "\n",
    "Pixel values range from 0–255. We scale them to 0–1 for numerical stability in the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = resized.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Min pixel value: {normalized.min():.2f}\")\n",
    "print(f\"Max pixel value: {normalized.max():.2f}\")\n",
    "print(f\"Data Type: {normalized.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-4",
   "metadata": {},
   "source": [
    "## Step 4: Data Augmentation\n",
    "\n",
    "We apply simple transformations to increase dataset diversity. Note: We use the *original* (0-255) image for OpenCV functions, as some don't like floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "augment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip Horizontal\n",
    "flipped = cv2.flip(resized, 1)\n",
    "\n",
    "# Increase Brightness (Manual method to avoid overflow/underflow)\n",
    "# We convert to int16 to prevent wrapping (255+1 = 0), then clip.\n",
    "bright_temp = resized.astype(np.int16) + 50\n",
    "bright = np.clip(bright_temp, 0, 255).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(flipped)\n",
    "plt.title(\"Flipped\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(bright)\n",
    "plt.title(\"Brightness Increased\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
